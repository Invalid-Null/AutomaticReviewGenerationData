<DOCUMENT>
100 years of scaling up fluidized bed and circulating fluidized bed reactors
Highlights
•
Reviews 100 years of development and commercialization of fluidized bed reactors
•
Overviews key commercial fluidized bed applications
•
Provides perspectives of prospective processes that can leverage fluidization
•
Traces scale-up tools in the past, present and future
Abstract
This year, 2022, we celebrate the 100-year anniversary of the commercialization of the fluidized bed reactor. In those years, many new processes have been developed, with many of them considered breakthrough technologies, replacing technologies that were no longer considered competitive. Fluidized beds have the advantages of superior heat transfer and the ability to continuously move solids during operation, along with a list of other attributes. As a result, processes spanning coal and biomass gasification, pyrolysis, fluidized catalyst cracking, acrylonitrile, polyethylene, oxychlorination, and polycrystalline silicon have prospered with the application of fluidized bed technology. Expect that list to continue with current efforts in chemical looping, plastic pyrolysis, methane pyrolysis, and propane dehydrogenation, to name a few.
In the past 100 years, the landscape of fluidized beds and circulating fluidized bed reactors has grown in numbers and applications. With those applications comes 100 years of scaling up and optimizing those fluidized beds. We have seen engineering go from an incremental approach to a more fundamental approach using sophisticated models and relevant cold flow experimentation. That engineering work process is still changing. With the onset of better computational platforms, models, and experimental techniques, combined with better statistical tools (e.g., machine learning) and control systems (e.g., artificial intelligence), the application of fluidized bed technology will require less capital, less operating costs, and allow for commercialization in less time.
Graphical abstract
Download : Download high-res image (158KB)
Download : Download full-size image
1. Introduction
In the past 100 years, chemical reactors have seen a significant technological leap in capabilities and applications. The historical developments of fluidized bed and circulating fluidized bed processes have been an essential part of that leap. Fluidized beds have the advantage of superior heat transfer and the ability to continuously move solids during operation, among a list of other attributes. As a result, processes including coal and biomass gasification, pyrolysis, fluidized catalyst cracking, acrylonitrile, polyethylene, oxychlorination, and polycrystalline silicon have benefited from the application of fluidized bed technology.
Researching and developing new fluidization technology and application has also seen a technological leap. Scale-up efforts have gone from incremental and Edisonian pilot units to tools such as advanced modeling, relevant cold flow testing, and pilot plant units tied to machine learning analysis. Here we discuss the history of fluidized bed applications and the engineering process that made it happen.
2. History of commercial fluidization
It is hard to believe that the technological age we have been seeing for the last two decades is nothing unique. At the turn of the last century, the world was going through another technological age. However, instead of the internet and all it brings, it was in chemical processing and all it brings. Arguably this new age became apparent with the commercialization of the Haber process, where hydrogen and nitrogen were directly combined to produce ammonia. Developed in 1909 by Fritz Haber and Robert Le Rossignol, it was purchased by BASF and scaled up into operation by 1910 under Carl Bosch. Both Haber and Bosch were awarded the Nobel Prize in 1918 and 1932, respectively. The original reactor stands as a monument at the BASF headquarters in Ludwigshafen, Germany.
The commercialization of the Haber process and other processes such as chloro-alkyl cells, Herreshoff process, Semet-Solvay process, cyanamide process for nitrogen fixation, phenol-formaldehyde plastic, and bakelite all happened within 20 years at the turn of the century [1]. These developments sparked the concept of unit operation and cemented the relevancy of chemical engineering. It also sparked the development of non-traditional reactors, of which the Winkler process was part. As shown in Fig. 1, a wide array of fluidized unit operations has been developed over the years. Some of the more notable developments with respect to coal gasification, fluidized catalytic cracking, chemical looping combustion and hydrogenation, production of acrylonitrile, polyethylene, and polycrystalline silicon are presented in the following subsections.
Download : Download high-res image (326KB)
Download : Download full-size image
Fig. 1. Some industrial fluidized bed and circulating fluidized bed processes.
2.1. Coal gasification
In December 1921 at BASF, Fritz Winkler mirrored his knowledge of the motion of boiling fluids to invent the first successful fluidized bed [2]. His invention was directed toward coal gasification, which provided a range of gas and liquid fuels, including hydrogen for BASF's ammonia plant. The fluidized bed had the added benefit of being co-mixing coal with carbonized zinc chloride for sulfur removal, a contaminant for the hydrogen stream. Winkler's invention offered several advantages over the traditional gasifiers [3,4] in that the fluidized bed provided good mixing, excellent heat transfer, and the ability to add (coal) and remove (ash) during operations. The first fluidized bed gasifier was commercialized in 1926. A schematic diagram of his process is shown in Fig. 2. A stirring rod was added near the distributor to remove the ash. Air was delivered too near the top of the bed. A bulbous expansion defined the freeboard to minimize the loss of the fines with the product gases. The coal was fed with a screw feeder into the bed [[5], [6]].
Download : Download high-res image (221KB)
Download : Download full-size image
Fig. 2. Winkler process (based on ref. [4]).
The Winkler's design heralded a host of breakthrough technologies, defined as sudden advances in knowledge and technique [7], resulting in existing ones having to adapt to compete or exit the market altogether. Such processes that benefited from Winkler's original concept span next-generation gasification, fluidized catalyst cracking, acrylonitrile production, Fischer Tropsch synthesis, polyolefin production, chemical looping, titanium dioxide production, and oxychlorination processes. Table 1 lists representative technologies. As highlighted in this review, the developmental pathways of these breakthrough technologies are often as fascinating as the engineering details that made them possible.
Table 1. Selected fluidized bed and circulating fluidized bed unit operations over 100 years.
Application Unit Operation Industry Approximate Commercialization
Acrylonitrile Fluidized Bed Chemicals SOHIO in 1959
Biomass Gasification Fluidized Bed Petrochemical, Chemical
Biomass Pyrolysis Fluidized Bed Petrochemical Ensyn in 1989
Catalytic Oxidation (CatOx) Fluidized Bed Chemical
Chemical Looping (Gas Feeds) Circulating Fluidized Bed Energy
Chemical Looping (Coal Feeds) Moving Bed Energy OSU/B&W Pending
Coal Gasification (Winkler) Fluidized Bed Petrochemical BASF in 1921
Combustion (BFB) Fluidized Bed Energy Foster Wheeler in 1977
Combustion (CFB) Circulating Fluidized Bed Energy Foster Wheeler in 1981
Fischer Tropsch (Hydrocol) Fluidized Bed Chemicals 1946
Fischer Tropsch (Synthol) Circulating Fluidized Bed Petrochemcial SASOL in 1955
Fluid Coke Tandem Fluidized Beds Petrochemical ExxonMobile in 1958
Fluidized Catalytic Cracking (FCC) Circulating Fluidized Bed Petrochemical Standard Oil of New Jersey in 1942
Hydrogen Chloride (HCl) Tandem Fluidized Beds Chemicals Arad in 1960
Iron Ore Roasting Fluidized Bed Mining BASF in 1953
Maleic Anydride (FBR) Fluidized Bed Chemicals Mitsubishi in 1970
Maleic Anhydride (CFB) Circulating Fluidized Bed Chemicals DuPont in 1996
Methane to Olefins (MTO) Fluidized Bed Petrochemical UOP Honeywell/Norsk Hydryo in 1995
Methane Pyrolysis (Decarbinization) Fluidized Bed Energy Pending
Phthalic Anhydride Fluidized Bed Chemicals Sherwin Williams in 1928
Plastic Pyrolysis Fluidized Bed Petrochemical
Polycrystalline Silicon Fluidized Bed Electronics Ethyl in 1989
Polyethylene (Unipol) Fluidized Bed Chemicals Union Carbide in 1968
Propane Dehydrogenation (FCDh) Circulating Fluidized Bed Chemicals Dow, Pending
Titanium Dioxide Fluidized Bed Metal then Pigments Kroll in 1948 followed by DuPont
Uranium Purification Fluidized Bed Mining
Vinyl Acetate Monomer (VAM) Fluidized Bed Chemicals BP in 2001
Vinyl Chloride Monomer (Oxychlorination) Fluidized Bed Petrochemical Oxy Vinyls in 1986
Fig. 3 shows the history of gasification, demonstrating its initiation more than 300 years ago. Gasification, which converts carbonaceous raw materials like coal and biomass into fuel or chemical feedstock, has been proven as a simple, robust and versatile technology through the centuries. While combustion appears to serve the same role of transforming carbonaceous materials into gases, two critical advantages of gasification relative to combustion are worth noting: (i) the product gases from combustion are of little value, but that from gasification are valuable; and (ii) combustion releases energy from chemical bonds, but gasification condenses energy into chemical bonds [8].
Download : Download high-res image (656KB)
Download : Download full-size image
Fig. 3. History of gasification.
As overviewed by Basu [8], the first large-scale gasification feedstock was wood, then coal, to produce charcoal. The value of the product gas (syngas) was proven in 1733, but it was only employed for practical use as town gas for street lighting in 1798 and thereafter popularized by the early 1800s. Nonetheless, the gas was produced through an inefficient process with low yields and low reliability. The Winkler process changed some of those issues. Solids can be fed and removed continuously, and the temperature was well controlled, resulting in less tar buildup in the reactor. Subsequently, significant improvements to the Winkler process were made in 1936 with the Lurgi process, which involved a pressurized fluidized bed, a cyclone, loop-seals, and heat recovery coils. In particular, the Lurgi process transformed the Winkler technology to a circulating fluidized bed loop, which allowed for larger units and higher throughputs, resulting in a fifteenfold increase in capacity. Indeed, the Lurgi process is recognized as the world's first large-scale circulating fluidized bed process [6]. In the 1950s, SASOL bought the rights to the Lurgi process.
In the 1950s, oil from the Middle East replaced gasification for transport fuel and chemical production. The abundance of natural gas negated the need for coal or biomass gasification, as steam reforming took center stage for generating syngas from natural gas and naphtha. In the 1960s, it was realized that fluidized bed gasifiers were convection limited, which spurred the development of the circulating fluidized bed gasifier or entrained flow gasifier. As shown in Fig. 4, the circulating fluidized bed combustor consisted of a dense bed and a lean freeboard that emptied into a large cyclone then into a superheater, evaporator, economizer, etc.
Download : Download high-res image (251KB)
Download : Download full-size image
Fig. 4. Circulating fluidized bed combustor.
The 1973 oil embargo, whereby OPEC (Organization of Arab Petroleum Exporting Countries) limited the United States and other western countries of oil, spurred the advancement of alternative technologies like gasification for energy independence. Gasification was revived for producing gas for heating and chemical feedstock that largely was derived from petroleum. Concurrently, increasing environmental awareness motivated the large-scale development of integrated gasification combined cycle (IGCC) power plants. In the last couple of decades, interest in gasification has been renewed in view of global warming and political issues. In particular, the focus has been on converting renewable raw materials such as biomass into syngas [[9], [10]]. Thereby, low-value feedstocks are upcycled, leading to more versatile uses because the quality of the gas produced can be controlled [11].
In the 21st century, gasification has made the third resurgence. Reduced oil reserves and carbon emission has moved this technology back into the limelight. However, the focus is more on biomass than coal, or a mixture of the two feedstocks instead of coal alone. Valmet has several gasification technologies with more than 150 MW capacity that focus on biomass and other waste feedstocks [11]. Although the size pales in comparison to some coal gasifier plants reaching up to 600 MW [12], the limitation is more logistics than technology. The bulk density of biomass limits the effective transportation range compared to coal. As a result, smaller is better in this case.
2.2. Fluidized catalytic cracking (FCC)
The development of the fluidized catalyst cracking process is a story for the history books and not just a chemical engineering history book, as shown in Fig. 5. In the late 1800's, fuel production was focused on kerosene, used primarily for lighting, which was made from the vaporization and subsequent crude separation of naptha. Later, caustic was added to remove the bulk of the sulfur and the odor that came with it. In 1910, electrical lighting replaced the kerosene lamp, and decimated the demand for the kerosene. The demand for fuels changed from kerosene to gasoline with the advent of the automobile. The new fuel demands were still coming from naptha and was still being produced from thermal cracking. This method was inefficient, having yields of less than 50%, and the product quality depended on the naptha source [14,15].
Download : Download high-res image (890KB)
Download : Download full-size image
Fig. 5. History of petroleum cracking with a focus on FCC operations.
In the late 1920s, Eugene Jules Houdry introduced catalytic cracking, providing higher yields and octane levels [[16], [17], [18]]. Commercial production using catalytic cracking began in 1937, but there was an issue. Catalytic cracking produces highly unsaturated hydrocarbons, or coke, that plug the pores of the catalyst in a matter of seconds. Coking is reversible, and the catalyst can be regenerated with air or oxygen, but the short operating duration for the catalyst precluded any degree of economic relevance. In addition, temperature control during regeneration was complicated, with too high of a temperature causing permeant damage to the catalyst. The next-generation catalyst cracker used large millimeter-sized catalyst pellets embodied by the Thermofor catalytic cracking (TCC) process that used two moving beds [19]. Continuous regeneration was at hand, but the process was complex and scaling up was challenging.
In 1940, the geopolitical upheaval was already in progress, and World War II was inevitable. The United States was motivated to significantly increase high-octane aviation gasoline [14,15]. The Catalytic Research Association (CRA) was formed and consisted of the Standard Oil Company (now ExxonMobil), M.W. Kellogg Company (now KBR), Anglo-Iranian Oil (now BP), Royal Dutch Shell, Texaco, and Universal Oil Products (now UOP-Honeywell) [20]. All of these companies have been actively engaged in independent catalytic cracking research for the prior 20 years. The dire global circumstances forced the collective sharing of the technology. Challenges such as managing pressure drop, erosion, attrition, aeration, etc. that each of these companies have been experiencing had solutions resting with what used to be their competitors [21]. Part of that sharing covered the work of Warren K. Lewis and Edwin R. Gilliland of the Massachusetts Institute of Technology under the funding of Standard Oil Company of New Jersey, which suggested that a low-velocity gas-catalyst lift would provide the circulation and residence time needed for catalyst cracking. From this, the circulating fluidized bed concept was born.
Within a few months, the CRA, with Kellogg leading the way, built a pilot plant unit at the Standard Oil refinery in Baton Rouge, LA. It was a success and led the way to the first large-scale Geldart Group A circulating fluidized bed cracker on that same site in less than three years. This is called the Model 1 Fluid Catalytic Cracker (FCC) [20], as shown in Fig. 6 [13]. Construction was completed on May 1st, 1942, and operation remarkably began on May 25th of that same year. The unit consisted of a regenerator that feeds solids into a hopper, which allows the solids to be recycled back to the regenerator. Regenerated catalyst are sent to the riser with an expander to provide more residence time. From the riser, the now spent catalyst are sent to another hopper then to the regenerator. A total of 34 more FCC units were constructed by 1945. Incredibly, it only took five years from conception to 35 operational commercial-scale plants.
Download : Download high-res image (211KB)
Download : Download full-size image
Fig. 6. Standard oil company model 1 FCC unit based on ref. [13].
There were several significant technologies developed during World War II, such as computers, penicillin, jet engines, atomic bomb, etc., but the two that had the most significant impact on the outcome of the war were radar and the FCC operation. The allied forces had almost unlimited access to fuel, including airplane fuel, whose much higher octane allowing the allied forces to fly higher and faster than their better-engineered counterparts.
Optimization of the FCC continued after the war. UOP came up with the side-by-side design in the mid-1950s, while Shell devised riser cracking in 1956 [13]. As the unit configurations improved, the catalysts also were continuously upgraded. A breakthrough on the catalyst front came in the form of high-activity zeolite developed by Socony-Mobil (currently Mobil), which was implemented in FCC units in 1964 to give enhanced gasoline yields and selectivity, and remains widely used [14].
Today, the FCC units remain technological marvels. Atomizing feed nozzles, lifting pots, spent catalyst distributors, short residence time riser termination, catalyst coolers, and structured packing for stripping have made these units viable and efficient. Even heavy residual oils are on the menu with technology from Technip Energies and the two regenerator configurations called R2R™ [[22], [23], [24]] or UOP's catalyst cooler design [25]. Product yields are further enhanced with new riser termination technology such as Technip Energies RSS™ [26] or UOP's VSS™ [27]. Also, UOP has developed a spent catalyst recirculation loop, RXCAT™, that decouples the catalyst circulation rate from the heat generated in the regenerator [28,29].
The global petroleum refining capacity is expected to expand as three billion people enter the middle class by 2030 [30]. The number of patents filed for FCC catalysts still sees healthy growth in recent years, with approximately half from Asia. Currently, FCC remains a relevant technology as the need for transportation fuels in the form of gasoline and diesel grows, and may be transformed into biofuels and carbon capture.
However, the future of FCC operations may be in question. The global capacity for refining fell by 730,000 b/d to 79.8 million b/d in 2020 (Reuters, 2022). The gasoline demand is projected to continue to decrease, leaving the major markets tied to FCC operations to middle distillates and aviation fuel (IEA, 2020). There are still decades of opportunities, but other product blends, biofuels, carbon sequestering, and repurposing operations are being considered [31].
2.3. Acrylonitrile
Acrylonitrile production was commercialized in Germany in 1930, followed by additional production in the USA [32]. It quickly found applications as a copolymer in Buna N rubber. Today it is used in the making of nylons, resins, thermoplastics, fibers, and elastomers as a monomer or comonomer. The original production used an ethylene oxide and hydrogen cyanide route over alumina catalyst. As one can imagine, the multi-stepped production involved careful engineering and operational guidelines to manage the flammability and toxicity of the process. In the late 1940s, another route was explored, which involved the ammoxidation of propylene. A process based on propylene ammoxidation would be a single processing step and have fewer safety constraints. However, this reaction is much more exothermic with a heat of reaction of over 500 KJ/mol. In 1957, Standard Oil of Ohio (Sohio, now part of INEOS) developed a catalytic ammoxidation process using bismuth molybdenum oxide catalyst at 450 °C, which provided good selectivity toward acrylonitrile [33]. The high heat of reaction was managed using a fluidized bed reactor as temperature control was critical to managing thermal decomposition, which compromises product yields. In 1960, a commercial Sohio process was born. Today, 90% of all commercial acrylonitrile production use fluidized bed reactors based on the Sohio process.
Fig. 7 provides a schematic drawing of a typical fluidized bed reactor configuration used for the ammoxidation of propene with ammonia and air in a fluidized reactor. The commercial version of these reactors spans 3 to 10 m, and operate at temperatures of 400 to 500 °C and pressures of 1 to 2 bars. At 10% excess, the air is typically fed at the bottom through a distributor plate where ammonia and propene are fed through a sparger array (i.e., pipe grid). Sets of cooling tubes are used to maintain near isothermal operations. The freeboard space is equipped with a train of primary, secondary, and even tertiary cyclones [18]. There can be more than a dozen of these cyclones in one reactor.
Download : Download high-res image (254KB)
Download : Download full-size image
Fig. 7. Propene ammoxidation in a fluidized bed reactor.
Gas residence times in these reactors are short, on the order of 5 to 10 s, and backmixing can be an issue [34]. It has been proposed that the addition of baffles in the fluidized bed can limit this backmixing and enhance product yields [35].
2.4. Polyethylene
The history of polyolefins started with polymethylene in the 1890s [36]. Fig. 8 presents the timeline of notable developments. Also known as alkenes, olefins are hydrocarbon molecules with double carbon‑carbon bonds. Polymerization of olefins leads to linear high molecular weight thermoplastic polyolefins, which were commercialized almost a century ago in 1931. Polyolefins constituted only 20% of the global polymer market in 1960 but quickly dominated 60% by 1995 [37]. This rise of polyolefin materials is an amazing feat, second to no other material because of the versatility in utilization and competitive cost. Polyethylene and polypropylene are the key polyolefins.
Download : Download high-res image (576KB)
Download : Download full-size image
Fig. 8. History of polyolefin with emphasis on gas-phase production.
The first commercial, high-molecular weight polyolefin was polyisobutylene (PIB) in 1931, about a century after the discovery of isobutylene in 1825, and remains a core business for BASF to date [37]. Regarding polyethylene, which represents the largest volume of thermoplastics produced in the world (80 million tons in 2013), commercial manufacturing started later in 1938. Yet, this was a high-pressure process, and capital costs were significant compared to other polymers at the time. A key breakthrough in the early 1950s came in the form of catalytic polymerization that enabled the production of linear, high-density polyethylene and other polyolefins at significantly lower pressures [36,38]. Polypropylene production only started in 1957 [36], but the growth is expected to propel it to have similar market shares as polyethylene [37]. As both polyolefin industries continue to grow, plastic recycling has become an area of active research [39].
Before 1960, polyolefins, primarily polyethylene, were made in autoclave reactors, and due to high pressure (3 to 130 barg), scale-up was limited. In addition, it was still a solution-based process (i.e., isoparaffinic fluids), and the separation of the solution from the product (polyethylene) was non-trivial. In 1957, Donald Norwood of Phillips (now Chevron-Phillips) invented the loop reactor, which slashed production costs by 75%. Norwood's invention made polyethylene competitive on the polymer market as no solution was needed, and the reactor was better at limiting dead zones, which often resulted in plugging. The first commercial loop reactor was started up in 1961. Still, the loop reactor had its limitation. Scale-up was still limited, and molecular weight distributions of the polyolefins could be broad, which is especially detrimental for low-density polymers. In 1968, Union Carbide (now Dow) developed the gas-phase polymerization reactor called the Unipol process, which is a completely different take on polymer reactors [[40], [41]]. As shown in Fig. 9, the fluidized bed had an expanded freeboard to remove the need for cyclones, which were prone to plugging. Low catalyst concentrations are injected and dispersed into the bed where the polymerization reactions occur on the catalyst. Polyethylene particles are produced and grow as polymerization continues on and around the catalyst. The gas-phase process was lower in capital and operating costs, and provided unsurpassed quality for low-density polyethylene (LDPE) and high-density polyethylene (HDPE). In 1989, new developments in constrained geometry catalysts resulted in these units being well-suited for linear low-density polyethylene (LLDPE) production.
Download : Download high-res image (138KB)
Download : Download full-size image
Fig. 9. Unipol gas phase fluidized bed reactor.
Temperature control can be an issue for these units, and runaway reactions can happen. In 1984, it was proposed that the recycle stream could be liquified and that liquid injected back into the bed [42]. The resulting heat of vaporization in the bed helps control the temperature of this exothermic process. Reactors operating in this configuration are said to be running in condense mode. Another issue with the gas-phase polymerization reactors is electrostatics. Charge buildup on the polyethylene particles can result in deposits on the walls of the reactor in the freeboard region. At some point, these wall deposits can dislodge from the walls and collapse into the bed, a phenomenon called sheeting, which results in premature shut-down [43].
In 2018, approximately 40% of the world's polyethylene production was done using fluidized bed reactors, and most that of polypropylene involves fluidized bed reactors. Reactor designs have improved and varied. The Dow Unipol and LyondellBasell Spherilene reactors still utilize the expanded freeboard in lieu of cyclones. The Innovene reactor has a cylindrical shape and uses cyclones for solids recovery. Plugging can still be an issue, but eductors are added to the diplegs to suck the polymer out of the cyclones and transport it back into the bed.
2.5. Chemical looping
Chemical looping or chemical looping combustion (CLC) has been at the forefront of research since 2000. In chemical looping technology, solid intermediates act as chemical carriers that cyclically undergo redox reactions [270,271]. CLC is an illustrative example of chemical looping, in which particulate metal oxide provides oxygen for oxidation reactions so combustion can be performed in the absence of nitrogen [270]. Thus, CO2 can be captured easily, as the main products of combustion will be steam and CO2 [270,271], and the particulate metal oxide reduced in the combustion reactor can then be looped to an air reactor to be regenerated (i.e., oxidized) before returning to the combustion reactor [270]. Notably, CLC has been reported earlier by Knoche and Richter in the early 1960s [43,44]. The concept of chemical looping beyond combustion was seen much earlier, starting with the work of Howard Lane in the early 1900s [45]. The concept was also applied to other processes in the early 1990s with butane dehydrogenation [46] and maleic anhydride [47]. Today that list is growing. Even catalyst cracking [48] and propane dehydrogenation [49] are being explored. However, most applications of chemical looping have been directed toward gasification [50], biomass conversion [51], methane combustion [52], coal combustion, gasification for syngas [50], or methanol production from coal [52].
The CLC process typically uses two fluidized beds, a circulating fluidized bed, or a loop of moving beds [[53], [54]]. The circulating solids are referred to as carriers rather than catalysts, although some carriers can also be catalytic. A carrier is typically a metal-metal oxide, or matrix of metal and metal oxides, that can go through thousands of cycles of reduction and oxidation. As shown in Fig. 10, the oxidation step extracts oxygen from the air feed in an air reactor. The metal oxide is then circulated to the other fuel reactor, where that oxide is reduced by the combustion of a hydrocarbon on the metal oxide or uncoupling of the oxygen from the metal where the combustion occurs in the gas phase (CLOU).
Download : Download high-res image (200KB)
Download : Download full-size image
Fig. 10. The chemical looping concept.
Chemical looping provides for segregation of effluent streams, with one being concentrated CO2 and the other being nitrogen. In traditional combustion reactors, the flue gas contains nitrogen with CO2, a difficult separation. With CLC, the concentrated CO2 effluent stream is well-suited for subsequent sequestration and storage. Another advantage is that chemical looping with a suitable carrier can provide greater conversion and selectivity than traditional reactors. Indeed, pilot studies have shown CLC provide carbon efficiencies of 87% compared to traditional units with a carbon efficiency of 82% [54].
Fan et al. [54] divided chemical looping into two classifications: one involves the generation of a concentrated CO2 stream for subsequent storage, while the other involves the generation of products other than CO2 (i.e., non-combustion). The latter mostly focused on hydrogen production (CLH) from biomass [51], coal [55], and methane [52,56]. The Ohio State University has developed an effective CLH process similar to that of steam-methane reforming, except the iron‑iron oxide carrier is in circulation using a moving bed. Water is cracked to hydrogen via oxidizing the reduced iron oxide catalyst. The iron oxide catalyst is then reduced with a methane feed that provides a concentrated CO2 stream with water. They reported a 5% increase in gas efficiency and a 6% increase in thermal efficiency compared to the conventional steam methane reforming process [52].
2.6. Polycrystalline silicon
The photovoltaic industry would be nowhere as competitive without the production of the polycrystalline silicon in fluidized bed reactors. The more traditional Siemens rod reactor process, developed in the 1950s, is more common with about 60% of the market in 2012. However, that market is eroding as the fluidized bed reactor route gains prominence due to economics. The Siemens process produces a high-quality product at the expense of high energy consumption, batch operation, and low single-pass conversion [57]. Specifically, the Siemens process is based on the chemical vapor deposition (CVD) of monosilane or trichlorosilane (TCS), with the latter being the dominant feedstock. Although TCS decomposes at 468 °C, much higher temperatures of 900 to 1100 °C are needed to limit the incorporation of chlorine atoms in the silicon rods [58]. The rods grow to a specified diameter and are then removed as the product.
In 1989, Ethyl Corporation developed a fluidized bed reactor process for this CVD route [59,60]. Silane was decomposed in the presence of hydrogen onto silicon seed particles in a fluidized bed reactor at temperatures of 620 to 650 °C. At steady-state, the bed had a particle size distribution ranging from 150 to 1500 μm, with a median particle size of 700 μm. As shown in Fig. 11, the resulting particles are extracted from the bottom while seed particles are fed in from the top. The process is well suited for the decomposition of silane and TCS, but with the higher temperatures needed for TCS, the fluidized bed reactors tend to be constructed of graphite.
Download : Download high-res image (138KB)
Download : Download full-size image
Fig. 11. Polycrystalline silicon production in a fluidized bed.
The fluidized bed reactor process is not without its challenges. With graphite reactors, heating is limited to the walls, which limits scale-up due to heat transfer challenges from the decreased surface to reactor volume ratio of larger units. Fines build-up in the freeboard region can also be a problem. Fines in the freeboard can be found in all fluidized beds, but for this process, the unreacted feed gas produce small crystallites in the cooler freeboard region [58]. The fines tend to agglomerate and cause blockage.
The first commercial operation to produce polysilicon in a fluidized bed was with MEMC Electronic Materials (now SunEdison) in Pasadena, Texas in 2006, which has shuttered. Other companies such as REC, Wächer, and Hemlock Semiconductor have followed suit to implement fluidized beds for polysilicon manufacturing.
2.7. New routes
Only a fraction of the history of fluidized beds has been disclosed here, and this story is far from over. Fluidized bed processes such as titanium dioxide, fluid coking, vinyl acetate, roasting, oxychlorination, and catalytic oxidation have all made significant impacts on economic feasibility compared to their predecessor. Yet, innovations using fluidized beds and circulating fluidized beds are far from finished. New processes continue to be developed and will likely have a similar impact on company bottom lines and society at large.
The pyrolysis of plastic as an alternative to plastic recycling is a good example of this innovation. As advancements in pyrolysis of biomass in fluidized beds continue, the pyrolysis of plastic waste is a progression of that effort. Menzel, Perkow, and Sinn [61] presented the first fluidized bed process for plastic pyrolysis in 1973 [62]. Additional research in this area was performed in the 1990s by Kaminsky et al. [[63], [64], [65]] with products such as benzene-toluene-xylene (BTX), heating fuels, and aliphatic oils. Several pilot-plant studies have been done on the process by companies such as Akzo, BP-Amoco, Battelle, BASF, Mitsui, etc. [62].
The fluidized bed process is well-suited for plastic pyrolysis. The excellent temperature control limits the cyclization side reactions. The absence of moving parts provides better reliability and scalability compared to other routes using extruders [66]. However, as with most pyrolysis processes, oxygenates, tars, and chlorides tend to hinder product quality and operability. This has sparked research in the catalytic cracking of plastics to provide a more directed product mix while operating at lower temperatures. Like all other cracking reactions, coking and limited catalyst concentrations in the riser need to be managed [67,68].
Although still in the early-stage research and development, methane pyrolysis (or methane decomposition or methane decarbonization) is seeing significant activity in the US [69]. Methane pyrolysis uses high-temperature metals to crack methane into hydrogen gas (turquoise hydrogen) and solid carbon. Thus, no CO2 is produced, unlike blue hydrogen, which involves steam cracking and CO2 production, albeit amenable for sequestering. Typically, methane pyrolysis is performed using plasma, molten salt, or with thermocatalytic decomposition. Kvaerner and Monolith Materials use the plasma torch process, and while conversions are high, the quality of the carbon is low. Karlsruhe Institute of Technology (KIT) and Netherlands Organization for Applied Scientific Research (TNO) have molten salt processes that provide good quality carbon, but they need to be separated from the molten salt. The thermocatalytic fluidized bed process using alumina, nickel, and/or iron-based catalyst [70] shows promise and is championed by several companies, including Hazer and C-Zero.
The Fischer Tropsch process has seen several flavors of fluid-granular fluid operations. SASOL started large-scale commercialization using a circulating fluidized bed and then migrated toward a slurry reactor (i.e., slurry phase distillate (SPD) process) [71]. There is growing interest in doing Fischer Tropsch reactions in a three-phase ebullated bed reactor, which provides the liquid carrier needed for easy product removal and high concentrations of the catalysts to provide good productivity, which can be a challenge with slurry reactors.
The last new process of note using fluidized bed technology is direct propane dehydrogenation (PDH). Nawaz et al. [72] and Chu [73] at Tsinghua University proposed such a process using a platinum tin catalyst in a fluidized bed that provides 95% selection to propylene in lab studies. In 2019, Dow announced fluidized catalytic dehydrogenation (FCDh) technology to selectively produce propylene. The technology can be implemented using existing mix-feed crackers (i.e., ethylene crackers). Dow's FCDh technology received both the R&D100 and ICIS Process Technology Innovation awards in 2017 [74].
So, the future of fluidized beds and circulating fluidized beds seems to continue to expand boundaries with new products and/or more efficient processes. Yet, in its 100-year history, the design and scale-up of these unit operations have also been as significant. Often, the scale-up design methodology starts with recognizing what is important with the change of scales, followed by how to extrapolate those relationships to commercial size applications.
3. History of scaling up fluidization
3.1. Scale up challenges
The benefits of fluidization are numerous, but the biggest draw would be its superior heat transfer characteristics and the ability to move a large amount of solids while still in operation. The superior heat transfer paved a path for development of the acrylonitrile SOHIO process, the polyethylene Unipol process, the polycrystalline silicon fluidized bed process, and the Fischer Tropsch process. The heat transfer coefficients of a fluidized bed of Geldart Group A powder are on the order of 100 BTU/ft2∙hr∙°F or 570 W/m2∙°C, which is about ten times greater than that of a commercial plug flow reactor [75]. The ability to continuously circulate catalyst on the order of 50 tons per minute or more sealed the deal for FCC circulating fluidized bed, chemical looping, circulating fluidized bed combustors, etc. In many instances, these new processes were considered breakthrough technology and revolutionized their respective markets.
Despite the benefits of fluidized beds, some challenges limit their applications. The movement of solids, whether in a fluidized bed or circulating fluidized bed, adds challenges with solids losses either by particle attrition or poor classifier collection efficiency. Solids losses are perhaps one of the key hindrances in implementing fluidized bed or circulating fluidized bed processes. Even with a well-designed unit, the operating costs could be significant. Too little attention is given to the early-stage development of these units with regards to entrainment rates and particle attrition, both of which can have a significant effect on solids-loss rates.
Consideration of the scale needed for testing is essential. A fluidized bed study should not be done in a unit with a diameter smaller than 15 cm (6 in.) to capture hydrodynamic behavior close to that in a commercial-scale unit [80]. Preferably, such studies should be done at an even larger diameter unit. Bubbles drive the gas and solids flow, as well as the bed density [76]. Notably, bubbles are also influenced by walls. Thus, the hydrodynamic behavior of small-scale units can differ from that of commercial units. Volk et al. [77] showed that the bed density was directly related to the vessel diameter in going from 5 cm to 28 cm. Darton et al. [78] showed that bubbles increase in size as they rise through the bed. For Geldart Group A powders, bubbles reach an equilibrium bubble size of approximately 10 cm (4.5 in.) [79]. For Geldart Group B powders, bubbles do not have an equilibrium size and can exceed a meter in diameter given enough bed height. If scale-up parameters are obtained in too small of a unit, the bubble size, bubble rise velocity, and solids motion within the bed will not be representative of larger-diameter systems and will be inadequate for the design of a commercial-scale unit. At the proof-of-concept stage at smaller scales, slugging behavior could result in false negatives. In other words, research and development efforts cannot be limited to lab-scale observations, which means scale-up efforts may take more time and more money. Conversely, appropriately considering scale-up needs during the early stages of research and development stages may considerably reduce time and capital costs associated with process scale-up.
In short, bubbles are the dominant controlling factors in fluidized beds. They are collectively the engine that drives solids from the bottom of the bed to the top and then back down to the bottom in the wall region [81,82]. Also, bubbles and bubble hydrodynamics can dictate mass transfer [83]. Most fluidized bed reactors tend to be limited by this type of mass transfer in systems whereby the intrinsic kinetics is relatively fast. Notably, most commercial fluidized beds reactors operate in the turbulent fluidized bed regime rather than the bubbling fluidized bed regime. The bubbling fluidization regime is characterized by dispersed bubbles rising through the bed, whereas the individual identity of bubbles is lost in the turbulent fluidization regime and the bed exists in a chaotic state. The chaotic mixing in the turbulent fluidization regime offers better mixing, and thus mass transfer, than the bubbling fluidization regime. Despite having to deal with higher entrainment rates and the solids losses that may come with the turbulent fluidization regime, the increase in the mass transfer is significant enough to make it worthwhile. As shown in Fig. 12, for a first-order reaction achieving 90% conversion in a plug flow reactor, a bubbling fluidized bed would have a conversion on the order of 30%, much less than that of a plug flow or continuous stirred tank reactor. However, the conversion rises to over 80% in the turbulent fluidized bed reactor, close to that of the plug flow reactor. The chaotic bubble hydrodynamics and the resulting irregular bubble shape in the turbulent regime significantly impact mass transfer rates [84].
Download : Download high-res image (251KB)
Download : Download full-size image
Fig. 12. Schematic concept of a first order reaction achieving 90% conversion with various fluidized bed and circulating fluidized bed reactors of similar kinetics.
Both mass and heat transfer can be compromised for tall or dense fluidized beds of Geldart Group A powders [85]. The permeability of a fluidized bed of Geldart Group A powder is relatively low compared to Group B or D powders. As a bed gets taller or a powder with a higher (bulk) density is used, the gas compression at the bottom of the bed can be significant, which causes further reduction in the gas permeability [86]. This is not a design issue and is inherent to the gas properties in the fluidized bed. What results is the development of one or more chains of fast-moving bubbles, causing a phenomenon referred to as gas bypassing. The resistance to gas flow is lower in these fast-moving bubble chains, and as a result gas preferentially flows through these chains. When the majority of the gas is actually bypassing the bed, it results in inadequate mixing and thus poor reactor productivity, high temperature variations in the bed, and/or flooding of cyclones if the diplegs are in the defluidized zones [87].
Even a well-designed fluidized bed exhibit hydrodynamics that require thoughtful consideration, because back-mixing can be significant. Commercial-scale fluidized beds have significant back-mixing that can affect yields for intermediate productions or processes that have undesirable secondary reactions. A more plug flow behavior can be achieved in a fluidized bed using baffles that localize the solids circulations, analogous to CSTR's in series. Indeed, Snamprogetti correspondingly developed such a MTBE process [88].
For circulating fluidized beds, there are challenges associated with each constituent unit, like the regenerator, stripper, riser and standpipe. Solid circulation rates depend on the pressure balance of all the units in the loop. Starting up such a system is also non-trivial. Circulating fluidized beds are based on the principle that enough pressure can be built in the standpipe to move the solids in the correct direction and at the desired solids circulation rate. However, as with fluidized beds, bubbles need to be managed, and commercial-scale standpipes can be limited by regions of defluidization and high wall friction [89]. Even a well-designed and properly operating standpipe has its limits, an insight that is often realized after upgrades and retrofits. The bed height in a standpipe is not dictated by design but by the resulting pressure loop. In other words, the pressure drop across all other components such as the slide valve, riser, riser terminator, cyclones, stripper, and regenerator has to equal the pressure drop across the standpipe, which is based on the standpipe bed height [90]. The same can be said about cyclone diplegs, but this is usually a more localized effect.
As can be seen, there are many factors that need consideration with the design and scale-up of a fluidized bed or circulating fluidized bed. Fortunately, none of these challenges should be considered insurmountable. Scale-up tools and procedures exist today to address all, if not almost all, of them. The issues come when they are not addressed at all, not addressed early enough in the research and development process, or the unit has expanded beyond the original design specifications and prior solutions no longer apply. Just as the application of fluidized bed in wide-ranging fields has a fascinating history, so does the history of scaling up these unit operations.
3.2. Historic scale up procedures
One hundred years ago, research and development in fluidized beds were Edisonian, as in advancements were typically born from trial and error rather than a methodic, theory-based approach. Scale-up solutions were held in confidence within each company. It was not until 1940, with the formation Catalytic Research Association (CRA), that any trade secrets related to fluidized bed operations were exchanged, thanks to the turmoil of that era. As a result, fluidized bed technology increased in scale at factors of 30 to 150 times. For the development of early FCC units, the change in scale from lab-scale units to the pilot plants were on the order of 5 to 10 times, while pilot to demonstration plants were on the order of 20 to 50 times. The scale-up to the commercial unit was on the order of 50 to 150 times based on the regenerator volume. Even with a demonstration plant in place, commercial FCC units did not perform as well as their pilot-scale counterparts [76]. However, higher operation temperatures did make up for this deficiency.
The development of the Fluid coking process fared better with scale-up in the 1950s with Exxon [76]. The pilot unit was sized for 100 barrels/day, and the capacity of the first commercial plant was at 3700 barrels/day, a 37 times scale-up factor. Still, at the time, scale-up for plug flow reactors and CSTRs were on the order of 1000 to more than 10,000 times for commercial designs based on lab-scale show tubes or CSTRs.
Despite the advantages of fluidized beds, especially for exothermic reactions, traditional reactors were still being implemented, even if they required tube and shell reactors with 10,000 s of tubes. The multiple units for fluidized bed development were a significant obstacle in terms of capital costs and time. Needless to say, there was a demand for a faster and less expensive development path for fluidized bed applications. In 1960, a significant amount of research was directed toward bubble behavior and bed density behavior [[91], [92], [93], [94], [95], [96]]. Jet penetration length correlations became an important scale-up parameter with gas distributor designs [[97], [98], [99], [100], [101], [102]]. In the 1970s and 1980s, transport disengagement height (TDH) estimates and entrainment rate correlations became a key design parameter [103,104]. Indeed, without a reasonable estimate of the entrainment rate, cyclones could not be sized correctly. Although cyclones are fairly forgiving with respect to varying solids loadings, diplegs are not. Too high of an estimated entrainment rate results in too low of a solids flux in the dipleg, making it prone to plugging. Too low of an estimated entrainment rate results in an undersized dipleg, which can result in cyclone flooding.
In the 1990s, efforts were directed toward developing scaling laws much like that used with the scale-up of CSTRs. Glicksman [105] non-dimensionalized the governing equations of motion for both the solid and fluid phases to establish rules for scaling fluidized bed operations from ambient to high temperature and pressure conditions. The Buckingham [106] pi theory is the basis for this dimensionless group method for scaling. The premise is that scaling can be enabled by ensuring similarity of the dependent variables (such as bubble characteristics and fluid velocity) through judicious adjustments of length scale, particle density, and superficial velocity. The set of scaling laws stipulating equal bed geometry, Reynolds number, Froude number, the ratio of particle to fluid density, dimensionless particle size distribution and sphericity remains widely used to date in both experimental and simulation studies.
Horio et al. [107] subsequently reported that hydrodynamic similarity can be sufficiently ensured through similarity in the radial bubble distributions, as manifested in bubble coalescence, as well as bubble splitting and interstitial flow behavior. However, it was found by Glicksman [108] that the scaling rules applies only to the viscous limit but not the inertial limit. To address this, Glicksman et al. [109] reported a new set of scaling laws based on the ratio of gas to particle drag that are applicable in both the viscous and inertial limits. The dimensionless groups for scaling were revisited with the aid of a kinetic theory based computational fluid dynamics of fluidized particles, where the particle phase is modeled as a continuum [110]. Discrepancies were found in the scaling laws derived from the two methods because of the differences in the constitutive relations in the continuum, kinetic-theory based equations [110]. In particular, the kinetic-theory constitutive relations - based scaling dictate that the ratio of particle diameter to column diameter and particle collision parameters like restitution coefficient are important especially with radial hydrodynamics. None of these are accounted for in the earlier scaling laws based on governing equations for single particles.
However, implementation of these scaling laws is limited due to the over-constraints in fluidized particle systems in practice. In particular, the particle size appears in many dimensionless groups as it dominates a significant amount of the hydrodynamic behavior, but the ratio of the particle diameter to system diameter is a key dimensionless group for scale-up. Hence, changing the particle-to-system diameter ratio while keeping other relevant dimensionless groups constant, the key to scaling-up, can be problematic. This is because the bed hydrodynamics would differ when changing between Geldart Group classification as particle size is scaled down for the cold flow experiments. For example, a commercial fluidized bed designed to run with 1 mm particles would have a cold flow experiment that would need particles on the scale of 80 μm and a higher density. So, relying on the scale-up rules, the cold flow study is with Geldart Group A particles, whereas the commercial unit uses Geldart Group B particles. However, Geldart Group A particles have a lower bed permeability, greater bed expansion, and an equilibrium bubble size. On the other hand, the Geldart Group B particles have a higher bed permeability, less bed expansion, and no equilibrium bubble size. Plus, the resulting larger bubbles move faster up the bed. So, the hydrodynamics can be quite different. The scale-up rules can still be used and are still used today, but their limitations need to be fully understood.
At the same time as the development of scale-up rules, reduced order models (ROMs) or compartment models were being developed to capture the mass transfer between the bubble and the emulsion phases in fluidized beds. It started with the development of a two-phase theory by Davidson and Harrison [111], which proposed that the amount of gas that is needed to achieve fluidization is the total amount of gas that will go through the emulsion phase of a fluidized bed. Any additional gas added to the fluidized bed results in the formation of bubbles.
Kunii and Levenspiel [14] expanded on the two-phase theory by assuming three phases: an emulsion phase, a cloud phase, and a bubble phase. The emulsion and cloud phases were modeled as CSTRs with mass transfer between each of the phases. The bubble phase was modeled as a plug flow reactor with mass transfer to the cloud phase. The bubble size and the resulting extrinsic mass transfer (i.e., kLA) is the key parameter for the model.
Werther and Hartge [112] developed a similar model but with the two phases proposed earlier by Davidson and Harrison. Both phases were modeled as plug flow reactors for each phase with mass transfer between phases. As with the Kunii and Levenspiel model [14], the estimate for the mass transfer coefficients between phases is a key parameter.
Thompson, Bi, and Grace [113] also used a two-phase concept, but instead of the bubble phase and emulsion phase, they used the terminology of low-density and high-density phases. Both phases were modeled as plug flow reactors with mass transfer between phases. However, unlike Kunni and Levenspiel [14], or Werther and Hertge [112], the low-density phase was not constrained to a pre-determined bubble shape. The voidage used in the model was based on probability density functions, which expanded the use of this type of model toward turbulent fluidized beds and the irregular voidage shapes that it comes with.
Patience and Chaouki [114] applied this compartment modeling approach to reactions in riser reactors and the associated core-annulus profiles. One phase was the dense annulus, while the other was the more dilute core. As with the other models, the extrinsic mass transfer (i.e, surface area between phases) was a key driver for model accuracy. This limitation was addressed using radioactive argon tracer gas to define a relationship to estimate the core diameter and the surface area that comes with it.
All these models have one or more mass transfer coefficients between dilute and dense phases, and it is this mass transfer coefficient that tends to be a dominant effect on the modeling results. Yet, these models are based on macroscopic hydrodynamics, whereas in most fluidized beds and circulating fluidized beds, the mesoscale hydrodynamics drives the mass transfer and the gas-solid dispersion. This is the limitation of these models, as micromixing of both the gas and solid phase is not captured. Thus, the accuracy of the mass transfer or diffusion coefficient is paramount, which may not be an easy task. A review by Breault [115] examined gas and solid dispersion data reported in the literature along with several solids and mass transfer coefficient correlation. It was concluded that, for a similar vessel at similar operation, values span seven orders of magnitude for the mass transfer coefficient and five orders of magnitudes for the dispersion coefficient. In other words, without an accurate mass transfer between phases, these ROM models may be useful for proof of concept, in part, but not for scale-up.
3.3. Recent scale up procedures
Today's scale-up procedures are based on the foundation of what was done before. Computational fluid dynamic (CFD) and population balance models (PBM) have augmented earlier efforts with scaling laws and reduced order models. The combination of expertise, i.e., cold-flow experiments coupled with CFD models, can eliminate at least one intermediate scale-up unit that has been previously needed. The elimination of one testing facility can result in a three-year reduction in development time and tens of millions of dollars in cost.
3.3.1. CFD modeling
Unlike ROM models, CFD models can capture the heterogeneous, mesoscale flow structures in fluidized beds and circulating fluidized beds, which are often driving the mass transfer and/or gas-solids dispersion, as well as heat transfer and interphase momentum transfer (i.e., drag). For the CFD modeling of fluidized beds and circulating fluidized beds, there are a few fundamental choices. The common model is based on the Naiver Stokes equations for both phases in an Eulerian (continuum) framework and is commonly referred to as the two-fluid model (TFM) [116]. Additional closures are needed for the collisional stresses in the solid phase and the drag between both phases. The collisional stresses were closed leveraging the work focused on inelastic particle collisions in Couette flow by Lun et al. [117]. Their work proposed a granular temperature variable to capture the particle velocity fluctuations and the perturbations of those fluctuations, thereby providing solutions for shear stresses (“solids viscosity”) and normal stresses (“solids pressure”). The equations are analogous to the Kinetic Theory of Gases, and hence this is called the Kinetic Theory of Granular Flow (KTGF) [118], and the boundary conditions that go with them [119].
For application to fluidized beds and circulating fluidized beds, some issues need to be addressed. A better agreement with the radial profile in a riser was found with a revised granular temperature at the wall boundary [120]. An unrealistic sensitivity to the coefficient of restitution (i.e., the elasticity of particle-to-particle collisions) used in the KTGF [121] was addressed by adding a solids turbulence term [122]. Kashiwa and van der Heyden [123] expanded this concept by adding another interphase momentum transfer term using the dissipation of solids turbulence to gas turbulence. This additional momentum transfer term was to better account for the backmixing common in low-velocity risers.
The drag force, which ties the two phases to each other, also needs to be captured. Notably, both commercial fluidized beds and risers tend to be drag-dominated. In a standpipe, the difference in velocities between the two phases becomes more equal due to the higher bed density and lower velocities. Yet, most drag models used in commercial fluidized bed simulations are decades old and based either on single particle terminal velocities or packed bed pressure drops, while solids concentrations in fluidized beds and circulating fluidized beds reside between the two [124].
Furthermore, the drag is dependent on the mesoscale hydrodynamics, suggesting that grid resolutions must be properly set for simulations of commercial operations. Hrenya and Fullmer [125], as well as Wang et al. [126], proposed that mesh spacing needs to be three times the particle diameter (i.e., on the order of 200 μm) for Geldart Group A powders to capture these mesoscale structures and ensure grid resolution independence. A similar argument was proposed by Milloli et al. [127]. Agrawal et al. [128] found this can be relaxed to ten times the particle diameter in dilute particle flows. For a typical FCC regenerator, such mesh spacing would result in 109 cells, which is 100 times greater than the capability of most two-fluid codes.
The workaround would be to reformulate the drag as a subgrid model using a process called filtered two-fluid modeling [129,130] or spatially averaged two-fluid [131] modeling. These models are based on a partial ordering of a better defined subset that serves as a base. Consequently, larger grids can be used, and such models have been applied to commercial-relevant fluidized beds and circulating fluidized beds [132].
Even with a subgrid model, the role of clustering still needs to be addressed. McMillian et al. [133] visualized the clustering of Geldart Group A and B particles in a fluidized bed, a liquid jet in a fluidized bed, and in a circulating fluidized bed riser. Such clustering behaviors have a dominating effect on the hydrodynamics in terms of entrainment, bubble hydrodynamics, and back-mixing. Additionally, no one clustering mechanism applies to all situations. In a fluidized bed, Coulombic forces seem to apply [[134], [135], [136], [137], [138]]. In the presence of a liquid, capillary action on a monolayer scale may be dominant [133]. Even condensed capillaries between particles in humid conditions can influence fluidized bed behavior [139,140]. In a riser, hydrodynamics forces may be at play in influencing drag minimization.
Indeed, drag minimization was addressed by Li et al. [[141], [142], [143]] with an energy minimization multi-scale (EMMS) model. An average drag coefficient is determined from the drag coefficient of the particles and the particle clusters (i.e., heterogeneity) [[144], [145], [146]]. Filtered drag models have been formulated to capture drag-induced clustering as well [129]. Both methods work well for drag- or turbulence-induced clusters, but the clustering due to inter-particle forces tend to be more elusive. Most drag models and corrections to the drag models are limited to capturing clustering in lower-velocity fluidized bed, which can result in overestimating the entrainment rates by 1000 times. As noted above, this is an issue with the design of the cyclone diplegs.
The clustering induced by interparticle force or capillary force has been addressed by adding a cohesion term in the drag model itself [147]. Others addressed this by adding a cluster size correction to the drag model [148,149]. Still, such corrections are too system-specific. As noted in Royer et al. [150], particle clustering was tied to the surface morphology. Smoother particles were much more prone to clustering than rough particles owing to a trade-off between the Coulombic forces and the rotational momentum transfer of colliding particles [138]. A recent analysis on the influence of interparticle forces on system behavior showed that collision-dominated systems can be characterized by the critical kinetic energy for particles to avoid agglomeration, whereas systems dominated by frictional contacts can be characterized by the maximum cohesive force between particles [151]. Distinguishing and identifying the limits for these energy-based or force-based description of cohesive particle flows provides guidance for the appropriate cohesive model for a system, e.g., force- or energy-based balance for determining agglomerates sizes in a system [151]. Unfortunately, direct prediction of interparticle force - induced clustering remains elusive.
Another challenge with the two-fluid models is capturing the particle size effect. It is not just the particle size of the bed material that drives the bed hydrodynamics, but also the particle size distribution, especially for Geldart Group A powders. The addition of fines to a fluidized bed of Group A powder can significantly decrease the bed density [152]. The difference in fines level can be significant on influencing gas bypassing as well. Yet, the commonly used two-fluid model uses one representative particle size, and it is unclear what that one particle size should be. However, this can be addressed in the two fluid model by propagating the moments of the particle size distribution instead of specifying just one particle size [153,154], commonly referred to as the quadrature-based method of moments (DQ-MOM or FCMOM) based on the anisotropic Gaussian closure. There are several methods for this integration [155,156]. Validation against data related to the third challenge problem by PSRI with the DOE showed that the bed density of a fluidized bed of Geldart Group A particles was in better agreement when the particle size distribution was used, as shown in Fig. 13 [157].
Download : Download high-res image (140KB)
Download : Download full-size image
Fig. 13. Bed densities for a 0.9-m diameter fluidized bed of FCC powder at 0.3 m/s superficial gas velocity simulated with one particle size (monodispersed) and the whole particle size distribution (polydispersed) via DQ-MOM, compared to experimental data.
Murray et al. [158] found that at least five moments were needed to capture the particle size distribution effect in fluidized beds accurately. Six particle species (i.e., size bins) were recommended to describe the particle size distribution or polydispersity, although that is dependent on the depth of the analysis. The number of recommended particle species could range from three to eight, depending on the analysis and the complexity of the particle size distribution.
Even with capturing the effect of the particle size distribution, most two-fluid models are built on the assumption of equipartition of granular energy between all particle sizes. In other words, all particles have the same granular energy despite being a small or large particle. Galvin et al. [159] showed that such an assumption results in an over prediction in the level and rate of segregation in a fluidized bed.
Polydisperse kinetic theory is generally categorized into two groups: multi-fluid models and mixture models [160,161]. For both model types, a mass balance is solved for each solid species (e.g., each particle size considered). For the multi-fluid approach, separate momentum and granular energy balances are solved for each species considered [160]. Mixture momentum and granular energy balances are solved for the mixture model, and the velocity and granular temperature of each species can be determined from the mixture velocity and mixture temperature [160]. The multi-fluid and mixture models can be applied beyond capturing particle size distributions within a single particle type, as they capture differences in species mass and therefore can be used for density differences as well.
These polydisperse kinetic theory models can be used to predict a wide range of phenomena relevant to industrial fluidized bed behavior. In particular, these models allow for simulations of fluidized beds involving mixtures of different solid materials [162,163], sizes [[164], [165], [166]], reactions [161,167,168], attrition [165], and agglomeration [[169], [170], [171]]. Currently, the biggest bottleneck for polydisperse kinetic theories is the increased computational cost associated with solving additional conservation equations for multiple solid species. However, the benefits of predicting such phenomena with these polydisperse kinetic theory models are expected to soon out-weigh the computational costs.
Another approach toward modeling fluidized unit operation is using the Discrete Element Method (DEM) coupled with CFD called CFD-DEM. The particulate phase is described with Newton's equation of motion in a Lagrangian framework, whereas the fluid phase is captured using the Eulerian framework. As with the two-fluid models, interphase momentum transfer is captured by the drag force. CFD-DEM offers a more rigorous calculation for the collisional stresses; however, capturing the moment of impact requires an impractically small time step (i.e., hard-sphere collisions). As a result, most DEM simulations relax this requirement using a soft sphere approximation whereby some degree of overlap is allowed, and collisions are modeled with elastic and viscous constitutive equations using the Kelvin-Voigt model [172]. Also, the drag is modeled similar to that used for the two fluid model. Still, CFD-DEM tends to offer better numerical accuracy than most two fluid models, and allows for more straightforward incorporation of additional physics such as particle shape, interparticle forces, capillary bridging, etc. [[173], [174], [175]].
If a higher degree of accuracy is needed, direct numerical simulations (DNS) can be employed. An illustrative analogy for DNS is that the CFD cell sizes are much smaller than the particles (specifically, less than ten times the particle diameter), so the flow around each and every particle is resolved. Thus, a drag model is not needed as drag is simulated directly. As one can imagine, DNS is computationally intensive, and only the smallest of computational domains are considered, which thus may not be sufficiently representative of larger scales.
CFD-DEM suffers from the same limitation, though to a lesser degree. Currently, CFD-DEM can simulate approximately 107 particles [176,177]. An FCC regenerator could have on the order of 1014 particles, which means 1014 equations for the particle tracking plus another 106 or so equations for the Eulerian framework (i.e., fluid phase in each cell). CFD-DEM is used for smaller operations such as screw feeders, hoppers, chutes, etc., but remains limited in use with commercial-scale fluidized beds and circulating fluidized beds. Another use for CFD-DEM is to build constitutive models for particle stresses to use in the two-fluid model.
Coarse graining can make the simulation of these commercial units feasible with solutions obtainable in weeks instead of months. With coarse graining, particles of similar size, shape, and density in a cell can be combined into clouds or parcels to reduce the number of equations. However, in doing so, some of the mesoscale features such as particle clustering and bubble hydrodynamic can be missed [178]. Thus, whether to use a two fluid model or CFD-DEM is dependent on an assessment of the capabilities and constraints.
A third common approach to modeling commercial-scale fluidized beds and circulating fluidized beds is to use a DEM-Hybrid model or more appropriately the Multiphase Particle-in-Cell (MP-PIC) method or Dense Discrete Phase Model (DDPM). The carrier gas is treated as a continuum in an Eulerian framework using the Reynolds Averaged Navier Stokes (RANS) equations [179], which are coupled to “particle” entities in a Lagrangian framework [180]. As with CFD-DEM and DEM, particles are tracked in accordance with Newtonian mechanics, but the collisions are not. Collisions are captured with a collisions stress model (i.e., solid stress tensor) such as the KTGF model [181] or a packing fraction model such as that from Harris and Crighton [182]. The continuum derivative terms that treat the particle phase as a fluid are then mapped back to the grid to individual “particles” [180]. The MP-PIC method has the advantage of capturing full particle size or particle density distributions with less computational overhead than when capturing the actual collisions (as in DEM). As with CFD-DEM, coarse graining (i.e., particles are treated in groups, clouds or parcels) can be used to reduce the number of equations for particle tracking. With the collision calculation relaxed with coarse graining, the ability to simulate commercial-scale fluidized unit operations simulated with chemistry are close to reality. Such efforts have been undertaken for gasifiers [183], fluidized bed chlorinator [184], circulating fluidized bed [185], and calciner [186].
To summarize, Fig. 14 presents the modeling methods in terms of the tradeoff between level of details and computation cost.
Download : Download high-res image (553KB)
Download : Download full-size image
Fig. 14. Summary of models. The number of particles specified is based on current capabilities.
3.3.2. PBM modeling
Besides capturing the hydrodynamics with or without the extrinsic kinetics, capturing the particle attrition rates are also equally important. Currently, particle attrition rates, and consequently solids loss rates, for a new fluidized unit operation are based on the relative attrition rate from lab- and/or bench-scale tests. Unfortunately, a validated method for scaling up attrition rates from bench- and lab-scale testing to commercial-scale design remains elusive. Furthermore, even the simple comparative attrition assessment approach currently used lacks significant validation to offer low-risk decision making. Hence, the lack of a reliable particle loss rate from a proposed process limits the commercialization possibilities of the process. Indeed, catalyst loss rates can cost tens of millions of dollars annually. Such additional operating expenses can dramatically swing the economic viability of a proposed process.
A population balance model (PBM) can reduce this unknown and partially de-risk the commercialization of a fluidized unit operation [[187], [188]]. For particle attrition, a PBM is a mass balance [189] or volume balance [190,191] of each bin in a particle size distribution. Abrasion and fragmentation of particles means that bins of larger sizes feed bins of smaller sizes, with the rates of increase or decrease in each bin depending on the rate and nature of attrition. Such models have been used to describe the particle attrition and resulting solids loss rates for commercial-scale fluidized beds and circulating fluidized beds. Generally, attrition in fluidized beds and circulating fluidized beds can be linked to gas and liquid jets (from spargers, distributors and nozzles), and the primary cyclone (note that secondary cyclones handle much less solids than primary cyclones). Attrition from both sources can be characterized in terms of abrasion and fragmentation attrition, leading to changes in particle size distributions that can be captured by population balance modeling.
Notably, the PBM formulation and the associated solution are straightforward. However, the rate mechanisms for the particle abrasion and fragmentation need further development along with the breakage function that goes with fragmentation. These rate expressions are typically attrition source-specific empirical fits, usually to simple power-law expressions, i.e., limited to stochastic models [190,[192], [193], [194], [195]]. The lack of mechanistic attrition rate parameters and breakage rate functions limits the effectiveness of the PBM as a scale-up tool.
High-speed video analysis of particle attrition with jet cup attrition testing suggests that a more mechanistic model may be needed to understand attrition even within a bench-scale test unit [196]. Such mechanistic models are needed to reap the full potential of the PBM. No one attrition test method is considered universal, and some attrition test methods are simply flawed [197]. Hence, even the laboratory testing itself may be limited and more understanding is necessary to point to better attrition characterization methods. Certainly, more testing and research are needed in this area.
3.3.3. Experiments
Cold-flow testing is the process of building a representative test unit to measure the gas-solid hydrodynamics under more manageable conditions, typically nominal lab conditions and without chemical reactions. The gap between nominal lab conditions and actual operating conditions are bridged by conserving the fluidization regime (i.e., dimensionless particle size versus dimensionless gas velocity) [14] or the drag force. Indeed, many correlations have been obtained in such cold-flow units through this 100-year history.
A proper cold-flow testing program can provide (1) proof of concept of the process design and/or bed material, (2) validation data for various models being used for scale-up including reduced order models, numerical methods for fluid mechanics (e.g., CFD), and population balance models, and (3) additional data not captured by the above-noted models. Cold-flow testing is more than visual observations, and a good program typically incorporates a plethora of probes to assess various phenomena, including extraction probes [198], Pitot tubes [199], gas and solid tracers, dynamic force probes [200], voidage probes [201], high-speed optical probes [202], bubble hydrodynamic probes [203], capacitance tomography [204,205], Kelvin probes [206,207], and acoustic/ultrasonic probes [208].
With those probes in the appropriately sized unit, the key scale-up parameters can be revealed, including bed density, entrainment rate, particle clustering, attrition, bubble hydrodynamics, solids dispersion, mass transfer, heat transfer, solid radial and axial profiles, gas radial and axial profiles, cyclone grade efficiency, cyclone pressure drops, standpipe pressure build, standpipe aeration strategy, and (gas only and particle-laden) jet penetration lengths. These parameters are the basis for the design and reliability assessment of gas distributors, cyclones, diplegs, operating bed heights, transport disengagement heights, entrainment rates, attrition rates, solids circulation rates, etc. Table 2 provides a listing of typical scale-up parameters and effective suggested tools to obtain those parameters based on the knowhow accumulated to date. Often the more advanced tools need to be validated with simpler tests or analysis. This is true with the measurements for complete fluidization velocities, bed densities, jet penetration lengths, TDH, entrainment rates, gas and solid residence time distributions (RTDs), and heat transfer coefficients. For Geldart Group A materials, such testing can be done in cold-flow, pilot-scale units. For Geldart Group B materials, the unit diameter is dependent on the potential for slug flow. The test vessel diameter needs to be larger than two-thirds of the slug diameter, while keeping in mind the slug diameter for Group B materials will continue to grow with increasing bed heights.Some parameters cannot be obtained in a cold-flow, pilot-scale unit, such as the velocity that defines the onset of turbulent fluidization, which most commercial fluidized beds operate at. Other parameters include the kinetic properties, and radial and axial temperature distribution properties. The radial and axial temperature distribution in pilot plant studies can provide a good indication of fluidization quality, and are easier to obtain than through high-speed pressure responses or acoustics. Often, gas bypassing can be detected in this fashion as well. However, if in the commercial unit, the bed height is even taller (and thus the catalyst bed is more dense) or less fines are available, gas bypassing is still possible.
Table 2. Some necessary scale-up parameters for a fluidized bed reactor and the recommended tools to determine them.
Parameter Cold Flow Experimentation or Similar Study Existing Empirical Correlation or ROMs Advanced Modeling (i.e., CFD) Pilot Plant Studies Comments
Lab-Scale (≥ 15 cm) Cold-Flow, Pilot-Scale (≥ 90 cm) @ T; P
(≥ 15 cm)
Minimum fluidization velocity, umf X X
Minimum bubbling velocity, ubf X Does not scale well with pressure and temperature
Complete fluidization velocity, ucf X XX
Turbulent fluidization velocity, utr X X X Key scale-up parameter for turbulent fluidized beds
Bed density at umf X
Bed density at uo X X XX XX Key scale-up parameter
Jet penetration length X XX XX Often safety factors make this less important, still should be checked
Transport disengagement height, TDH X XX
Entrainment rates vs velocities X XXc XXc XX Key scale-up parameter
Bubble hydrodynamics X
Gas RTD X XXc XX Key scale-up parameter
Solids RTD
(if needed) X XXc XXp Key scale-up parameter with solids feeds
Fluidization quality X X Analysis of pressure or acoustic waveforms
Heat transfer coefficient X (no internals) X (with internals) XX XX XXp Often safety factors make this less important, still should be checked
Cyclone grade efficiency X X X Often done by vendor
Cyclone pressure drop X X X X Needed for dipleg sizing
Dipleg bed heights X X X X Key scale-up parameter
Bed attrition vs time on stream X X X Key scale-up parameters
Radial and axial temperature distribution X For evaluation of fluidization quality (i.e., gas bypassing) at temperature
Erosion X Key scale-up parameter
Yields X X X Key scale-up parameter
Catalyst deactivation X X X Key scale-up parameter
X denotes suggested.
XX denotes previous suggested task (denoted with X) is prerequisite.
XXp denotes improved outcome if previous suggested task (denoted with X) is performed.
XXc denotes “conditional” outcome reliability and previous suggested task (denoted with X) is prerequisite.
Some calculations are “conditional”, implying dependence on the particle properties and operating conditions. For example, entrainment is a key scale-up parameter, but correlations and CFD modeling likely significantly overestimates for Geldart Group A material or other materials prone to clustering [104]. Similarly, solids mixing is often overestimated with CFD models due to the equipartition assumption of the granular energy [159]. Heat transfer is another property that requires validation if a correlation or CFD model is being used for scale-up. Currently, the surface area is typically oversized to correct for expected errors for heat transfer. Having extra heat transfer banks in the fluidized bed is common as it helps with increases in productivity and provides mitigation for failure of other banks.
Combining cold-flow experimental studies with models validated against these cold-flow studies provides the path toward faster and less costly scale-up. A better understanding of pilot plant behavior (and understanding the gaps) allows for better designs of commercial units.
3.4. Tomorrow's scale up procedures
The technologies for fluidized and circulating bed scale-ups are rapidly advancing. Trying to predict where it ends up may not be fruitful, and such predictions are often biased. In the late 1990s, the US DOE Office of Scientific and Technical Information proposed the Vision 2020 program, where everything needed to scale up a chemical process would be done computationally [209]. Obviously, we are not there yet. Table 2 illustrates the gaps in today's scale-up efforts. No one test, correlation, model, or pilot plant study can provide what is needed for effective scale-up, but the combination of these tests, correlations, models, and pilot plant studies do provide more confidence and risk mitigation.
Based on today's observations, tomorrow's scale-up procedure will be based on more fundamental studies and better data analysis. A better understanding of the fundamental nature of particle hydrodynamics, such as clustering, breakage, multiphase hydrodynamics-induced drag, etc. could fill in the gaps needed with current modeling capabilities. Better probes will provide a better understanding of the hydrodynamics, and better materials (e.g., high-temperature resistance) for those probes could provide more in-situ analysis of pilot studies or even commercial-scale units. Better models will bridge the gap between what is observed and what can be reproduced in simulations. More comprehensive data-mining will make the bridge happen sooner. Artificial intelligence promises to provide a faster means toward optimized solutions.
3.4.1. Improvements with experiments
The development of better experimental techniques to provide more insights into particle behavior on the meso- and micro-scale continues. On the meso-scale, techniques such as capacitance tomography, pressure analysis, positron emissions, radioactive gas and particle tracking, ultrasonics, etc. can provide less probe-intrusive data on bubble and bulk particle behavior. Indeed, capacitance tomography has provided insights with risers [210], conveying lines [211] and bubble hydrodynamics in gas-solid, gas-liquid, and gas-liquid-solid fluidized beds [212,213]. Effective signal analysis of pressure fluctuations can also reveal meso-scale structures in fluidized beds [214,215]. Dynamic force probes can translate those transient pressures into dynamic forces on fluidized bed internals with the sensitivity to depict bubble impacts [200].
Positron emissions particle tracking (PEPT) can provide particle behavior in cyclones [216], standpipes [217], L-valves [218], fluidized beds [219], and circulating fluidized beds [220]. Radioactive gas and particle tracking provide data on gas and solids mixing, as well as core-annulus profiles in risers, and can be implemented in pilot and commercial units [221]. Ultrasonics can also be applied to pilot and commercial units. Cody et al. [222] were able to determine the granular temperature in a conveying line from the shock noise. The addition of ultrasonic probes on cyclones on a fluidized bed was able to determine the solids velocity and loading for each cyclone [223].
On the micro-scale, high-speed video coupled with borescope provides insights into particle momentum and the exchange of that momentum in multiphase flows. Such studies have provided insights into liquid atomization into a fluidized bed [133], radial distributions of particles and granular temperature in a riser [[224], [225], [226]], and particle attrition in a jet cup [196]. Similarly, Lee et al. used high-speed video to track free-falling particles and particle clusters between an electric field [136,137]. Smaller particles were decisively more negatively charged than the larger particle, and charge transfer was found be both electronic and ionic.
As piezoelectric detectors become smaller and more shape-specific, momentum probes may see additional applications in gas-solid flows. Such studies have been done to measure local volume fraction in risers [[227], [228]], wall stresses in risers [229], jet penetration lengths in fluidized beds, and also scouring of membranes in solid-liquid fluidized beds [273,274]. Today's detectors can be made significantly smaller without compromising the signal-to-noise ratio. As a result, less intrusive probes are possible and possibly smaller than the more popular fiber optic probes [201].
3.4.2. Improvements with Modeling
Obviously, advances in modeling with CFD will get more powerful just from increases in CPU/GPU speeds and memory architecture. The criteria for better grid and/or parcel resolution in the simulations are more obtainable with newer processors and servers.
However, as noted above, additional advances will be needed, for example, better descriptors for drag in fluidized beds and circulating fluidized beds. Currently, most drag models are based on single-particle terminal velocity or packed bed pressure drops [116]. Additionally, drag needs to address nearest-neighbor effects better, as shown by Yin and Sundaresan [230]. Some DNS work has been done in this area to better resolve the physics, but additional research in this area is likely needed [[231], [232], [233]].
For particles smaller than Geldart Group A powders, particle clustering needs to be addressed both in fluidized beds and risers [138]. Interparticle forces compromised by the rotational momentum and friction of the particles have been acknowledged to be at play, but a descriptor is needed to characterize such behavior in CFD models. LaMarche et al. [234] collected data and simulations on over 1000 different configurations, particle sizes, particle densities, and operating conditions that specifically target drag and particle clustering in fluidized beds. Such data is freely available at https://data.psri.org in the hope that better-suited and more-encompassing drag models can be developed for fluidized beds and risers. The realization of such improved models is potentially on the horizon, especially with artificial intelligence becoming viable in this area (see the next subsection).
For risers, both Geldart Group A and B powders exhibit particle clustering, with large particle clusters sometimes referred to as streamers. They have been well mapped in riser flow [[235], [236], [237]], but their mechanism for formation, stability, and instability is not well known. Particle clustering and streamer formation can be driven by a multitude of micromechanical interactions [125], even beyond the clustering and agglomeration due to interparticle attractive forces. Inelastic particle collisions, frictional contacts, and drag are sources of clustering as well. The nature and origins of these clusters are different and may impact CFD predictions differently, such as those which seems to stem from drag minimization [141,142] or turbulence-induced particle clustering [[123], [238]]. Interestingly enough, clusters may induce turbulence as well, as proposed by Patel et al. [239]. Identifying how these various sources of clustering impact the overall prediction of fluidized beds can potentially contribute to the mismatch between CFD predictions and experiments, thereby providing breakthrough improvements in the capabilities of commercial-scale CFD modeling.
The attrition models also need better constitutive equations. As noted above, most attrition rate models are simple power-law expressions, and some do not distinguish between abrasion and fragmentation. In order for PBM-based attrition models to predict attrition in new units and indicate attrition issues in existing units, a better, more mechanistic attrition model is needed, and perhaps better laboratory testing to support such models. Results reported by Bailey et al. [196] on attrition in a jet cup testing unit suggests particle attrition in such devices is not straightforward and cannot be described by a power-law expression. Recently, Ghods et al. [240] used CFD-DEM with Hertzian contact stresses to develop a more mechanistic model of particle attritions in gas jets in fluidized beds. About 98% of the particle attrition was found to be in the orifice zone of the jet.
3.4.3. Machine learning
Contrary to traditional simulation methods based on step-by-step codes, machine learning tools are based on training the system to link inputs and outputs based on past data, and thereby reduce the computational cost by circumventing the need to solve complex partial differential Eqs. [272]. Deciding between simulation methods (e.g., TFM versus CFD-DEM) often requires considering a tradeoff between enhanced solution detail at the expense of increased computational cost, or increased number of closures (i.e., decreased solution detail) but with less computational cost. To this end, machine learning, in which pattern recognition, classification and regression are key features, promises to mitigate the computation load if sufficient data are available for the training. Therefore, machine learning tools are becoming increasingly popular for obtaining adequate predictions and more mechanistic understanding, particularly in complex processes such as fluidization. Without any need for a priori understanding, our earlier studies demonstrated that machine learning tools could determine the relative dominance of the operating parameters (e.g., particle diameter, superficial gas velocity) on various fluidization phenomena (e.g., local mass flux, local segregation), as well as develop models with reasonable predictive accuracy [241]. Interesting findings include (i) monodispersity versus non-monodispersity of the particle system exerts a predominant influence on cluster characteristics [242]; (ii) the pressure drop across the riser alone is the most influential parameter by far on overall mass flux, such that it alone can be used to train models with reasonable predictability [243]; (iii) particles larger than the Sauter-mean are more correlated to bubble characteristics than smaller ones [244]; and (iv) particle properties influence entrainment in turbulent fluidization but not fast fluidization, while the radial position was the most dominant influence on segregation in fast fluidization but least in turbulent fluidization [245]. Machine learning has been applied in wide-ranging aspects, for instances, to simplify the analysis of electrical capacitance tomography measurements [212,246] (e.g., Warsito and Fan used neural networks to precondition the ill-posed reconstruction equations with capacitance tomography [212]), and to provide various predictions such as the performance of biomass gasifiers [247,248], characteristic velocities (e.g., minimum fluidization velocity [249], terminal velocity [250]), segregation behaviors in bidisperse solid-liquid fluidized beds [251], particle surface charge density [252], etc.
On the simulation front, machine learning has been applied to estimate drag [[253], [254], [255]] and intra-particle heat transfer [256], and also to generate hybrid models (e.g., CFD – neural network [257]) with improved accuracy and performance. Siddani et al. [258] found a machine learning algorithm could reproduce the flow field around an array of randomly distributed particles with adequate accuracy compared to the highly-resolved DNS simulations. Furthermore, Siddani et al.'s [258] algorithm reproduced the flow field with higher accuracy than a superimposable wake approximation based on pairwise particle interactions [259]. Using machine learning to predict fluid flow around particle arrays, once trained using DNS, could provide a faster alternative to building drag models by potentially reducing the overall number DNS simulations. Similarly, increased accuracy for more computationally feasible (e.g., coarse) simulations could be achieved via machine learning. Davydzenka and Tahmasebi [260] used machine learning algorithms trained from fine-grid simulations to improve prediction accuracy in course grid simulations, thereby increasing simulation speed but not at the expense of accuracy. Jiang et al. [254] used neural networks to predict the sub-grid drift velocity, which can be used for the filtered drag correction with a two-fluid model. Similarly, Zhu et al. [261] used neural network and extreme gradient to predict the filtered sub-grid drag correction, and Lu et al. [262] used neural networks regression to define a filtered drag model for a coarse grain CFD-DEM model.
Machine learning could also provide useful tools for the design of fluidization units, although a scouring of the literature unveiled only a limited application of such data-driven models. There are also other approaches available that have been applied to other fields. An example is the HEEDS optimization tool developed by Siemens, which automates analysis workflow and optimization methodology, and has been applied to processes including fuel oxidation [263,264]. Another interesting possibility is to employ Internet of Things (IoT) [[265], [266], [267]], which is promising for developing highly integrated smart industrial systems [268,269]. A network of smart sensors for monitoring key fluidization performance indicators in real time, coupled with decision-making tools based on machine-learning tools like an artificial neural network to adapt to evolving inputs and conditions, can potentially provide for better control as well as augment efficiency.
4. Summary
In summary, it has been a remarkable 100 years with respect to fluidization applications. It was an effort that resulted in breakthrough technologiesies for gasification, fluidized catalyst cracking, acrylonitrile, and polyethylene, and promises to do the same with new prospects such as methane cracking, carbon sequestering, decarbonization, and dehydrogenation. The next hundred years may also focus on the methodology for better scale-up of those applications. Research efforts are needed to bridge the persistent gaps in the knowledge base with respect to particle attrition, interparticle cohesion, clustering, turbulence, mass transfer, particle roughness and shape effects, drag, among others. Time to commercialization is crucial in today's economy, and the tools that are developed and used with tomorrow's scale-up efforts will have a decisive impact. Those tools will need better physics, better experiments, and better analysis.
Declaration of Competing Interest
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.
</DOCUMENT>

Examine the content within the supplied document to determine if it pertains to any form of propane dehydrogenation, including both Propane Dehydrogenation (PDH) and Oxidative Propane Dehydrogenation (ODH). If the document discusses either of these processes in the context of converting propane to propylene, please continue to assess the main scientific contributions as outlined in the subsequent steps.
1. Identify the catalyst that represents the main scientific contribution in the document.
2. Extract and detail the following information for this catalyst:
    - Name
    - Type: Metal, Metal Oxide, Single Atom, Alloy, Others
    - Composition Element(s) (chemical symbols)
    - If the Type is "Alloy":
        - Structure Type: Nanoparticulate Alloys, Intermetallic Compounds, Single-atom Alloys, Others
        - Preparation Method: Impregnation Methods, Heat Treatment, Surface & Support Methods, Solution-Based Methods, In Situ Synthesis, Chemical Methods, Physical Methods, etc.
    - Active Species Element(s) (chemical symbols)
    - Promoter Element(s) (chemical symbols, if any)
    - Support Material: Silica Oxide, Aluminum Oxide, Oxides, Carbides, Zeolites, Others
    - Conversion (%): Specify type (e.g., single-pass conversion, propane conversion, overall conversion)
    - Selectivity (%)
    - Stability (if in h-1 or convert to h-1)
    - Deactivation Rate(s) (value and units)
    - Propane Production Rate (value and units)
    - Propylene Yield (%)
    - Feed Composition and Ratio(s)
    - Propane Partial Pressure
    - Reaction Temperature (value and units)
    - Inlet Flow Rate (value and units)
    - Catalyst Loading or Gas Hourly Space Velocity (GHSV) (value and units)
3. Determine how the manuscript increases selectivity, conversion, and stability, focusing on improvements in catalyst preparation method, structural composition, process conditions, or reactor design.
4. Describe the specific performance enhancements (selectivity, conversion, stability) and summarize the advancement in one sentence.
5. Convert the stability to an hourly rate (h-1) if not already in that unit.
6. Identify whether the catalyst is utilized for Propane Dehydrogenation (PDH), a process that does not involve oxidation, or for Oxidative Propane Dehydrogenation (ODH), where an oxidative process is integral. Clarify the distinction between PDH, where propane is dehydrogenated to propylene without the presence of oxygen or other oxidizing agent, and ODH, which involves the oxidation of propane as a part of the dehydrogenation process to propylene.
7. Identify the feed gas composition utilized with the catalyst.
8. Determine if the feed gas contains an oxidizing agent.

Output the information in an XML format following the provided template.

<output>
	<Relevance>
		(Indicate yes or no)
	</Relevance>
	<IfRelated>
		<MainScientificContribution>
			<Catalyst>
				<Name>____</Name> <!-- N/A if not mentioned -->
				<Type>____</Type> <!-- Metal, Metal Oxide, Single Atom, Alloy, Others -->
				<CompositionElements>
					<Element>__Chemical Symbol__</Element>
					<!-- Add more elements as necessary -->
				</CompositionElements> <!-- N/A if not mentioned -->
				<AlloyDetails> <!-- Include only if Type is Alloy -->
					<StructureType>____</StructureType> <!-- E.g., Nanoparticulate Alloys -->
					<PreparationMethod>____</PreparationMethod> <!-- E.g., Impregnation Methods -->
				</AlloyDetails> <!-- N/A if not mentioned -->
				<ActiveSpeciesElements>
					<Element>__Chemical Symbol__</Element>
					<!-- Add more elements as necessary -->
				</ActiveSpeciesElements> <!-- N/A if not mentioned -->
				<PromoterElements>
					<Element>__Chemical Symbol__</Element>
					<!-- Add more elements as necessary -->
				</PromoterElements> <!-- N/A if not mentioned -->
				<SupportMaterial>____</SupportMaterial> <!-- N/A if not mentioned -->
				<ConversionTypes>
					<Type>____</Type> <!-- E.g., single-pass conversion, propane conversion, overall conversion -->
					<Value>__Value%__</Value>
					<!-- Add more types as necessary -->
				</ConversionTypes> <!-- N/A if not mentioned -->
				<Selectivity>__Value%__</Selectivity> <!-- N/A if not mentioned -->
				<StabilityOriginal>__Value (Original Units)__</StabilityOriginal> <!-- N/A if not mentioned -->
				<ConvertedStability>__Value (h-1)__</ConvertedStability> <!-- N/A if not mentioned -->
				<DeactivationRates>
					<Rate>__Value (Units)__</Rate>
					<!-- Add more rates as necessary -->
				</DeactivationRates> <!-- N/A if not mentioned -->
				<PropaneProductionRate>__Value (Units)__</PropaneProductionRate> <!-- N/A if not mentioned -->
				<PropyleneYield>__Value%__</PropyleneYield> <!-- N/A if not mentioned -->
				<FeedCompositionAndRatios>
					<Ratio>____</Ratio>
					<!-- Add more ratios as necessary -->
				</FeedCompositionAndRatios> <!-- N/A if not mentioned -->
				<PropanePartialPressure>____</PropanePartialPressure> <!-- N/A if not mentioned -->
				<ReactionTemperature>__Value (Units)__</ReactionTemperature> <!-- N/A if not mentioned -->
				<InletFlowRate>__Value (Units)__</InletFlowRate> <!-- N/A if not mentioned -->
				<CatalystLoadingOrGHSV>__Value (Units)__</CatalystLoadingOrGHSV> <!-- N/A if not mentioned -->
 				<TypeIdentify>____</TypeIdentify>  <!-- PDH or ODH -->
				<FeedGasComposition>
					<Component>____</Component>
					<Component>____</Component>
					<!-- Add more items as necessary -->
				</FeedGasComposition>
				<ContainsOxidizingAgent>____</ContainsOxidizingAgent> <!-- Yes or No -->
			</Catalyst>
			<PerformanceEnhancement>
				<EnhancementDetails>
					<!-- Specify the aspect(s) that has/have been enhanced (Selectivity, Conversion, Stability) -->
					<!-- For example, if Selectivity has been enhanced due to a specific preparation method, list it here -->
					<Aspect>____</Aspect> <!-- E.g., Selectivity, Conversion, Stability -->
					<ImprovedBy>____</ImprovedBy> <!-- E.g., Preparation Method, Structural Composition, Process Conditions, Reactor Design -->
					<SummaryOfAdvancement>____</SummaryOfAdvancement>
				</EnhancementDetails>
				<!-- Repeat the <EnhancementDetails> element if there are multiple enhancements -->
			</PerformanceEnhancement>
		</MainScientificContribution>
	</IfRelated>
</output>
